

<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="./">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>torch_staintools.normalizer package &mdash; Torch-StainTools 1.0.5 documentation</title>
      <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=b86133f3" />
      <link rel="stylesheet" type="text/css" href="_static/css/theme.css?v=9edc463e" />

  
      <script src="_static/jquery.js?v=5d32c60e"></script>
      <script src="_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script src="_static/documentation_options.js?v=d55fa986"></script>
      <script src="_static/doctools.js?v=9bcbadda"></script>
      <script src="_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="_static/js/theme.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="prev" title="torch_staintools.functional.utility package" href="torch_staintools.functional.utility.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="index.html" class="icon icon-home">
            Torch-StainTools
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="reference internal" href="modules.html">torch_staintools</a><ul class="current">
<li class="toctree-l2 current"><a class="reference internal" href="torch_staintools.html">torch_staintools package</a><ul class="current">
<li class="toctree-l3 current"><a class="reference internal" href="torch_staintools.html#subpackages">Subpackages</a><ul class="current">
<li class="toctree-l4"><a class="reference internal" href="torch_staintools.augmentor.html">torch_staintools.augmentor package</a></li>
<li class="toctree-l4"><a class="reference internal" href="torch_staintools.base_module.html">torch_staintools.base_module package</a></li>
<li class="toctree-l4"><a class="reference internal" href="torch_staintools.cache.html">torch_staintools.cache package</a></li>
<li class="toctree-l4"><a class="reference internal" href="torch_staintools.constants.html">torch_staintools.constants package</a></li>
<li class="toctree-l4"><a class="reference internal" href="torch_staintools.functional.html">torch_staintools.functional package</a></li>
<li class="toctree-l4 current"><a class="current reference internal" href="#">torch_staintools.normalizer package</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="torch_staintools.html#submodules">Submodules</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch_staintools.html#module-torch_staintools.version">torch_staintools.version module</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch_staintools.html#module-torch_staintools">Module contents</a></li>
</ul>
</li>
</ul>
</li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">Torch-StainTools</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="modules.html">torch_staintools</a></li>
          <li class="breadcrumb-item"><a href="torch_staintools.html">torch_staintools package</a></li>
      <li class="breadcrumb-item active">torch_staintools.normalizer package</li>
      <li class="wy-breadcrumbs-aside">
            <a href="_sources/torch_staintools.normalizer.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="torch-staintools-normalizer-package">
<h1>torch_staintools.normalizer package<a class="headerlink" href="#torch-staintools-normalizer-package" title="Link to this heading"></a></h1>
<section id="submodules">
<h2>Submodules<a class="headerlink" href="#submodules" title="Link to this heading"></a></h2>
</section>
<section id="module-torch_staintools.normalizer.base">
<span id="torch-staintools-normalizer-base-module"></span><h2>torch_staintools.normalizer.base module<a class="headerlink" href="#module-torch_staintools.normalizer.base" title="Link to this heading"></a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="torch_staintools.normalizer.base.DataInput">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">torch_staintools.normalizer.base.</span></span><span class="sig-name descname"><span class="pre">DataInput</span></span><a class="headerlink" href="#torch_staintools.normalizer.base.DataInput" title="Link to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">TypedDict</span></code></p>
<p>For future compatibility - e.g., moving average of stain matrix from same wsi which needs uri to identify.</p>
<dl class="py attribute">
<dt class="sig sig-object py" id="torch_staintools.normalizer.base.DataInput.img">
<span class="sig-name descname"><span class="pre">img</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">TYPE_IMAGE</span></em><a class="headerlink" href="#torch_staintools.normalizer.base.DataInput.img" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="torch_staintools.normalizer.base.DataInput.uri">
<span class="sig-name descname"><span class="pre">uri</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">str</span></em><a class="headerlink" href="#torch_staintools.normalizer.base.DataInput.uri" title="Link to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="torch_staintools.normalizer.base.Normalizer">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">torch_staintools.normalizer.base.</span></span><span class="sig-name descname"><span class="pre">Normalizer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">cache</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="torch_staintools.cache.html#torch_staintools.cache.tensor_cache.TensorCache" title="torch_staintools.cache.tensor_cache.TensorCache"><span class="pre">TensorCache</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">device</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rng</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">Generator</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#torch_staintools.normalizer.base.Normalizer" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="torch_staintools.base_module.html#torch_staintools.base_module.base.CachedRNGModule" title="torch_staintools.base_module.base.CachedRNGModule"><code class="xref py py-class docutils literal notranslate"><span class="pre">CachedRNGModule</span></code></a></p>
<p>Generic normalizer interface with fit/transform, and the forward call that will at least call transform.</p>
<p>Note that the inputs are always supposed to be pytorch tensors in BCHW convention.</p>
<dl class="py method">
<dt class="sig sig-object py" id="torch_staintools.normalizer.base.Normalizer.build">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">build</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="#torch_staintools.normalizer.base.Normalizer" title="torch_staintools.normalizer.base.Normalizer"><span class="pre">Normalizer</span></a></span></span><a class="headerlink" href="#torch_staintools.normalizer.base.Normalizer.build" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch_staintools.normalizer.base.Normalizer.fit">
<em class="property"><span class="pre">abstract</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">fit</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#torch_staintools.normalizer.base.Normalizer.fit" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch_staintools.normalizer.base.Normalizer.forward">
<em class="property"><span class="pre">abstract</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="#torch_staintools.normalizer.base.DataInput" title="torch_staintools.normalizer.base.DataInput"><span class="pre">DataInput</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#torch_staintools.normalizer.base.Normalizer.forward" title="Link to this definition"></a></dt>
<dd><p>Define the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch_staintools.normalizer.base.Normalizer.transform">
<em class="property"><span class="pre">abstract</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">transform</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwarags</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#torch_staintools.normalizer.base.Normalizer.transform" title="Link to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

</section>
<section id="module-torch_staintools.normalizer.factory">
<span id="torch-staintools-normalizer-factory-module"></span><h2>torch_staintools.normalizer.factory module<a class="headerlink" href="#module-torch_staintools.normalizer.factory" title="Link to this heading"></a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="torch_staintools.normalizer.factory.NormalizerBuilder">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">torch_staintools.normalizer.factory.</span></span><span class="sig-name descname"><span class="pre">NormalizerBuilder</span></span><a class="headerlink" href="#torch_staintools.normalizer.factory.NormalizerBuilder" title="Link to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>Factory Builder for all supported normalizers: reinhard, macenko, and vahadane</p>
<dl class="py method">
<dt class="sig sig-object py" id="torch_staintools.normalizer.factory.NormalizerBuilder.build">
<em class="property"><span class="pre">static</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">build</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">method</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Literal</span><span class="p"><span class="pre">[</span></span><span class="s"><span class="pre">'reinhard'</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="s"><span class="pre">'vahadane'</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="s"><span class="pre">'macenko'</span></span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sparse_stain_solver</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Literal</span><span class="p"><span class="pre">[</span></span><span class="s"><span class="pre">'ista'</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="s"><span class="pre">'cd'</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="s"><span class="pre">'fista'</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'fista'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sparse_dict_steps</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">60</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dict_init</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Literal</span><span class="p"><span class="pre">[</span></span><span class="s"><span class="pre">'zero'</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="s"><span class="pre">'transpose'</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="s"><span class="pre">'unif'</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="s"><span class="pre">'ridge'</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'transpose'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">concentration_solver</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Literal</span><span class="p"><span class="pre">[</span></span><span class="s"><span class="pre">'ista'</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="s"><span class="pre">'cd'</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="s"><span class="pre">'fista'</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="s"><span class="pre">'ls'</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'fista'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_stains</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">luminosity_threshold</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.8</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">perc</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">regularizer</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.01</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">maxiter</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">50</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lr</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tol</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">1e-05</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">use_cache</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cache_size_limit</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">-1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">device</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">load_path</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rng</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">Generator</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="#torch_staintools.normalizer.base.Normalizer" title="torch_staintools.normalizer.base.Normalizer"><span class="pre">Normalizer</span></a></span></span><a class="headerlink" href="#torch_staintools.normalizer.factory.NormalizerBuilder.build" title="Link to this definition"></a></dt>
<dd><p>build from specified algorithm name <cite>method</cite>.</p>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>concentration_algorithm = ‘ls’ May fail on GPU for individual large input (e.g., 1000 x 1000),
regardless of batch size. Therefore, ‘ls’ is better for multiple small inputs in terms of H and W.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>method</strong> – Name of stain normalization algorithm. Support <cite>reinhard</cite>, <cite>macenko</cite>, and <cite>vahadane</cite></p></li>
<li><p><strong>sparse_stain_solver</strong> – sparse solver for dictionary learning in Vahadane algorithm.
Support ‘ista’, ‘fista’, and ‘cd’.</p></li>
<li><p><strong>sparse_dict_steps</strong> – steps of iteration in dictionary learning in Vahadane algorithm.</p></li>
<li><p><strong>dict_init</strong> – code initialization method in dictionary learning in Vahadane algorithm.</p></li>
<li><p><strong>concentration_solver</strong> – solver to obtain the concentration. Default ‘fista’ for fast sparse solution on GPU.
Only applied to StainSeparation-based approaches (macenko and vahadane).
support ‘fista’, ‘ista’, ‘cd’, and ‘ls’. ‘ls’ solves the least square problem for factorization of
min||HExC - OD||, faster but no sparsity constraints. ‘ista’/cd enforce the sparse penalty but slower.</p></li>
<li><p><strong>num_stains</strong> – number of stains to separate. Currently, Macenko only supports 2. Only applies to <cite>macenko</cite> and
‘vahadane’ methods.</p></li>
<li><p><strong>luminosity_threshold</strong> – luminosity threshold to ignore the background. None means all regions are considered
as tissue. Scale of luminosity threshold is within [0, 1].  Only applies to <cite>macenko</cite> and
‘vahadane’ methods.</p></li>
<li><p><strong>perc</strong> – Percentile threshold in Macenko algorithm to find the minimum angular term. min  as 1 percentile
and max angular as (100 - perc) percentile. Default is 1.</p></li>
<li><p><strong>regularizer</strong> – regularizer term in ISTA for stain separation and concentration computation. Only applies
to <cite>macenko</cite> and ‘vahadane’ methods if ‘ista’ is used.</p></li>
<li><p><strong>maxiter</strong> – the max iteration in code updating of dictionary learning for stain matrix and
concentration estimation (e.g., ISTA)</p></li>
<li><p><strong>lr</strong> – learning rate for ISTA/FISTA-based optimization in code/concentration updating in ISTA/FISTA.
If None, the invert of Lipschitz constant of the gradient is used.</p></li>
<li><p><strong>tol</strong> – tolerance threshold for early convergence in ISTA/FISTA.</p></li>
<li><p><strong>use_cache</strong> – whether to use cache to save the stain matrix of input image to normalize.  Only applies
to <cite>macenko</cite> and ‘vahadane’</p></li>
<li><p><strong>cache_size_limit</strong> – size limit of the cache. negative means no limits. Only applies
to <cite>macenko</cite> and ‘vahadane’</p></li>
<li><p><strong>device</strong> – what device to hold the cache and the normalizer. If none the device is set to cpu. Only applies
to <cite>macenko</cite> and ‘vahadane’</p></li>
<li><p><strong>load_path</strong> – If specified, then stain matrix cache will be loaded from the file path. See the <cite>cache</cite>
module for more details. Only applies  to <cite>macenko</cite> and ‘vahadane’</p></li>
<li><p><strong>rng</strong> – seed or torch.Generator for any random initialization may incur.</p></li>
</ul>
</dd>
</dl>
<p>Returns:</p>
</dd></dl>

</dd></dl>

</section>
<section id="module-torch_staintools.normalizer.reinhard">
<span id="torch-staintools-normalizer-reinhard-module"></span><h2>torch_staintools.normalizer.reinhard module<a class="headerlink" href="#module-torch_staintools.normalizer.reinhard" title="Link to this heading"></a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="torch_staintools.normalizer.reinhard.ReinhardNormalizer">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">torch_staintools.normalizer.reinhard.</span></span><span class="sig-name descname"><span class="pre">ReinhardNormalizer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">luminosity_threshold</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#torch_staintools.normalizer.reinhard.ReinhardNormalizer" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#torch_staintools.normalizer.base.Normalizer" title="torch_staintools.normalizer.base.Normalizer"><code class="xref py py-class docutils literal notranslate"><span class="pre">Normalizer</span></code></a></p>
<p>Very simple Reinhard normalizer.</p>
<dl class="py method">
<dt class="sig sig-object py" id="torch_staintools.normalizer.reinhard.ReinhardNormalizer.build">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">build</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">luminosity_threshold</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#torch_staintools.normalizer.reinhard.ReinhardNormalizer.build" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch_staintools.normalizer.reinhard.ReinhardNormalizer.fit">
<span class="sig-name descname"><span class="pre">fit</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">image</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#torch_staintools.normalizer.reinhard.ReinhardNormalizer.fit" title="Link to this definition"></a></dt>
<dd><p>Fit - compute the means and stds of template in lab space.</p>
<p>Statistics are computed within tissue regions if a luminosity threshold is given to the normalizer upon
creation.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>image</strong> – template. BCHW. [0, 1] torch.float32.</p>
</dd>
</dl>
<p>Returns:</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch_staintools.normalizer.reinhard.ReinhardNormalizer.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#torch_staintools.normalizer.reinhard.ReinhardNormalizer.forward" title="Link to this definition"></a></dt>
<dd><p>Define the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="torch_staintools.normalizer.reinhard.ReinhardNormalizer.luminosity_threshold">
<span class="sig-name descname"><span class="pre">luminosity_threshold</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">float</span></em><a class="headerlink" href="#torch_staintools.normalizer.reinhard.ReinhardNormalizer.luminosity_threshold" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch_staintools.normalizer.reinhard.ReinhardNormalizer.normalize_helper">
<em class="property"><span class="pre">static</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">normalize_helper</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">image</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">target_means</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">target_stds</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mask</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#torch_staintools.normalizer.reinhard.ReinhardNormalizer.normalize_helper" title="Link to this definition"></a></dt>
<dd><p>Helper.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>image</strong> – BCHW format. torch.float32 type in range [0, 1].</p></li>
<li><p><strong>target_means</strong> – channel-wise means of template</p></li>
<li><p><strong>target_stds</strong> – channel-wise stds of template</p></li>
<li><p><strong>mask</strong> – Optional luminosity tissue mask to compute the stats within masked region</p></li>
</ul>
</dd>
</dl>
<p>Returns:</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="torch_staintools.normalizer.reinhard.ReinhardNormalizer.target_means">
<span class="sig-name descname"><span class="pre">target_means</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Tensor</span></em><a class="headerlink" href="#torch_staintools.normalizer.reinhard.ReinhardNormalizer.target_means" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="torch_staintools.normalizer.reinhard.ReinhardNormalizer.target_stds">
<span class="sig-name descname"><span class="pre">target_stds</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Tensor</span></em><a class="headerlink" href="#torch_staintools.normalizer.reinhard.ReinhardNormalizer.target_stds" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch_staintools.normalizer.reinhard.ReinhardNormalizer.transform">
<span class="sig-name descname"><span class="pre">transform</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#torch_staintools.normalizer.reinhard.ReinhardNormalizer.transform" title="Link to this definition"></a></dt>
<dd><p>Normalize by (input-mean_input) * (target_std/input_std) + target_mean</p>
<p>Performed in LAB space. Output is convert back to RGB</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> – input tensor</p></li>
<li><p><strong>*args</strong> – for compatibility of interface.</p></li>
<li><p><strong>**kwargs</strong> – for compatibility of interface.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>output torch.float32 RGB in range [0, 1] and shape BCHW</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="module-torch_staintools.normalizer.separation">
<span id="torch-staintools-normalizer-separation-module"></span><h2>torch_staintools.normalizer.separation module<a class="headerlink" href="#module-torch_staintools.normalizer.separation" title="Link to this heading"></a></h2>
<p>Note that some of the codes are derived from torchvahadane and staintools</p>
<dl class="py class">
<dt class="sig sig-object py" id="torch_staintools.normalizer.separation.StainSeparation">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">torch_staintools.normalizer.separation.</span></span><span class="sig-name descname"><span class="pre">StainSeparation</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">stain_alg</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="torch_staintools.functional.stain_extraction.html#torch_staintools.functional.stain_extraction.extractor.StainAlg" title="torch_staintools.functional.stain_extraction.extractor.StainAlg"><span class="pre">StainAlg</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">concentration_solver</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="torch_staintools.functional.concentration.html#torch_staintools.functional.concentration.implementation.ConcentrationSolver" title="torch_staintools.functional.concentration.implementation.ConcentrationSolver"><span class="pre">ConcentrationSolver</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_stains</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">luminosity_threshold</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.8</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rng</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">Generator</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cache</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="torch_staintools.cache.html#torch_staintools.cache.tensor_cache.TensorCache" title="torch_staintools.cache.tensor_cache.TensorCache"><span class="pre">TensorCache</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">device</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#torch_staintools.normalizer.separation.StainSeparation" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#torch_staintools.normalizer.base.Normalizer" title="torch_staintools.normalizer.base.Normalizer"><code class="xref py py-class docutils literal notranslate"><span class="pre">Normalizer</span></code></a></p>
<p>Stain Separation-based normalizer’s interface: Macenko and Vahadane</p>
<p>The stain matrix of the reference image (i.e., target image) will be dumped to the state_dict should torch.save().
is used to export the normalizer’s state dict.</p>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>concentration_algorithm = ‘ls’ May fail on GPU for individual large input (e.g., 1000 x 1000),
regardless of batch size. Therefore, ‘ls’ is better for multiple small inputs in terms of H and W.</p>
</div>
<dl class="py method">
<dt class="sig sig-object py" id="torch_staintools.normalizer.separation.StainSeparation.build">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">build</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">stain_alg</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="torch_staintools.functional.stain_extraction.html#torch_staintools.functional.stain_extraction.extractor.StainAlg" title="torch_staintools.functional.stain_extraction.extractor.StainAlg"><span class="pre">StainAlg</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">concentration_solver</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="torch_staintools.functional.concentration.html#torch_staintools.functional.concentration.implementation.ConcentrationSolver" title="torch_staintools.functional.concentration.implementation.ConcentrationSolver"><span class="pre">ConcentrationSolver</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_stains</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">luminosity_threshold</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.8</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rng</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">Generator</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">use_cache</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cache_size_limit</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">-1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">device</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">load_path</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="#torch_staintools.normalizer.separation.StainSeparation" title="torch_staintools.normalizer.separation.StainSeparation"><span class="pre">StainSeparation</span></a></span></span><a class="headerlink" href="#torch_staintools.normalizer.separation.StainSeparation.build" title="Link to this definition"></a></dt>
<dd><p>Builder.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>stain_alg</strong> – stain algorithm to use.</p></li>
<li><p><strong>concentration_solver</strong> – method to obtain the concentration. default ista for computational efficiency on GPU.
support ‘ista’, ‘cd’, and ‘ls’. ‘ls’ simply solves the least square problem for factorization of
min||HExC - OD|| but is faster. ‘ista’/cd enforce the sparse penalty but slower.</p></li>
<li><p><strong>num_stains</strong> – number of stains to separate. Currently, Macenko only supports 2. In general cases it is
recommended to set num_stains as 2.</p></li>
<li><p><strong>luminosity_threshold</strong> – luminosity threshold to ignore the background. None means all regions are considered
as tissue.</p></li>
<li><p><strong>rng</strong> – Optional. Seed for reproducibility.</p></li>
<li><p><strong>use_cache</strong> – whether to use cache to save the stain matrix of input image to normalize</p></li>
<li><p><strong>cache_size_limit</strong> – size limit of the cache. negative means no limits.</p></li>
<li><p><strong>device</strong> – what device to hold the cache and the normalizer. If none the device is set to cpu.</p></li>
<li><p><strong>load_path</strong> – If specified, then stain matrix cache will be loaded from the file path. See the <cite>cache</cite>
module for more details.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>StainSeparation normalizer.</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="torch_staintools.normalizer.separation.StainSeparation.concentration_solver">
<span class="sig-name descname"><span class="pre">concentration_solver</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference internal" href="torch_staintools.functional.concentration.html#torch_staintools.functional.concentration.implementation.ConcentrationSolver" title="torch_staintools.functional.concentration.implementation.ConcentrationSolver"><span class="pre">ConcentrationSolver</span></a></em><a class="headerlink" href="#torch_staintools.normalizer.separation.StainSeparation.concentration_solver" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch_staintools.normalizer.separation.StainSeparation.fit">
<span class="sig-name descname"><span class="pre">fit</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">target</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">concentration_method</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Literal</span><span class="p"><span class="pre">[</span></span><span class="s"><span class="pre">'ista'</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="s"><span class="pre">'cd'</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="s"><span class="pre">'fista'</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="s"><span class="pre">'ls'</span></span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#torch_staintools.normalizer.separation.StainSeparation.fit" title="Link to this definition"></a></dt>
<dd><p>Fit to a target image.</p>
<p>Note that the stain matrices are registered into buffers so that it’s move to specified device
along with the nn.Module object.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>target</strong> – BCHW. Assume it’s cast to torch.float32 and scaled to [0, 1]</p></li>
<li><p><strong>concentration_method</strong> – method to obtain concentration. Use the <cite>self.concentration_method</cite> if not specified
in the signature.</p></li>
</ul>
</dd>
</dl>
<p>Returns:</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch_staintools.normalizer.separation.StainSeparation.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cache_keys</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">Hashable</span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tensor</span></span></span><a class="headerlink" href="#torch_staintools.normalizer.separation.StainSeparation.forward" title="Link to this definition"></a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> – input batch image tensor in shape of BxCxHxW</p></li>
<li><p><strong>cache_keys</strong> – unique keys point the input batch to the cached stain matrices. <cite>None</cite> means no cache.</p></li>
<li><p><strong>**kwargs</strong> – For compatibility of parent class signatures.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>normalized output in BxCxHxW shape and float32 dtype. Note that some pixel value may exceed
[0, 1] and therefore a clipping operation is applied.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="torch_staintools.normalizer.separation.StainSeparation.get_stain_matrix">
<span class="sig-name descname"><span class="pre">get_stain_matrix</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference internal" href="torch_staintools.functional.stain_extraction.html#torch_staintools.functional.stain_extraction.extractor.StainExtraction" title="torch_staintools.functional.stain_extraction.extractor.StainExtraction"><span class="pre">StainExtraction</span></a></em><a class="headerlink" href="#torch_staintools.normalizer.separation.StainSeparation.get_stain_matrix" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="torch_staintools.normalizer.separation.StainSeparation.num_stains">
<span class="sig-name descname"><span class="pre">num_stains</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">int</span></em><a class="headerlink" href="#torch_staintools.normalizer.separation.StainSeparation.num_stains" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch_staintools.normalizer.separation.StainSeparation.repeat_stain_mat">
<em class="property"><span class="pre">static</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">repeat_stain_mat</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">stain_mat</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">image</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tensor</span></span></span><a class="headerlink" href="#torch_staintools.normalizer.separation.StainSeparation.repeat_stain_mat" title="Link to this definition"></a></dt>
<dd><p>Helper function for vectorization and broadcasting</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>stain_mat</strong> – a (usually source) stain matrix obtained from fitting</p></li>
<li><p><strong>image</strong> – input batch image</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>repeated stain matrix</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="torch_staintools.normalizer.separation.StainSeparation.stain_matrix_target">
<span class="sig-name descname"><span class="pre">stain_matrix_target</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Tensor</span></em><a class="headerlink" href="#torch_staintools.normalizer.separation.StainSeparation.stain_matrix_target" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="torch_staintools.normalizer.separation.StainSeparation.target_concentrations">
<span class="sig-name descname"><span class="pre">target_concentrations</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Tensor</span></em><a class="headerlink" href="#torch_staintools.normalizer.separation.StainSeparation.target_concentrations" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch_staintools.normalizer.separation.StainSeparation.transform">
<span class="sig-name descname"><span class="pre">transform</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">image</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cache_keys</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">Hashable</span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tensor</span></span></span><a class="headerlink" href="#torch_staintools.normalizer.separation.StainSeparation.transform" title="Link to this definition"></a></dt>
<dd><p>Transformation operation.</p>
<p>Stain matrix is extracted from source image use specified stain seperator (dict learning or svd)
Target concentration is by default computed by dict learning for both macenko and vahadane, same as
staintools.
Normalize the concentration and reconstruct image to OD.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>image</strong> – Image input must be BxCxHxW cast to torch.float32 and rescaled to [0, 1]
Check torchvision.transforms.convert_image_dtype.</p></li>
<li><p><strong>cache_keys</strong> – unique keys point the input batch to the cached stain matrices. <cite>None</cite> means no cache.</p></li>
<li><p><strong>**kwargs</strong> – For compatibility of parent class signatures.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>normalized output in BxCxHxW shape and float32 dtype. Note that some pixel value may exceed
[0, 1] and therefore a clipping operation is applied.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="module-torch_staintools.normalizer">
<span id="module-contents"></span><h2>Module contents<a class="headerlink" href="#module-torch_staintools.normalizer" title="Link to this heading"></a></h2>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="torch_staintools.functional.utility.html" class="btn btn-neutral float-left" title="torch_staintools.functional.utility package" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2024, YZ.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>